@misc{univmap,
  title = {universal-pos-tags},
  author = {Slav Petrov},
  howpublished = {\url{https://github.com/slavpetrov/universal-pos-tags}},
  note = {Accessed: 2017-12-27},
  year={2017}
}



@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@Article{Brants2004,
author="Brants, Sabine
and Dipper, Stefanie
and Eisenberg, Peter
and Hansen-Schirra, Silvia
and K{\"o}nig, Esther
and Lezius, Wolfgang
and Rohrer, Christian
and Smith, George
and Uszkoreit, Hans",
title="TIGER: Linguistic Interpretation of a German Corpus",
journal="Research on Language and Computation",
year="2004",
month="Dec",
day="01",
volume="2",
number="4",
pages="597--620",
abstract="This paper reports on the TIGER Treebank, a corpus of currently 40,000 syntactically annotated German newspaper sentences. We describe what kind of information is encoded in the treebank and introduce the different representation formats that are used for the annotation and exploitation of the treebank. We explain the different methods used for the annotation: interactive annotation, using the tool ANNOTATE, and LFG parsing. Furthermore, we give an account of the annotation scheme used for the TIGER treebank. This scheme is an extended and improved version of the NEGRA annotation scheme and we illustrate in detail the linguistic extensions that were made concerning the annotation in the TIGER project. The main differences are concerned with coordination, verb-subcategorization, expletives as well as proper nouns. In addition, the paper also presents the query tool TIGERSearch that was developed in the project to exploit the treebank in an adequate way. We describe the query language which was designed to facilitate a simple formulation of complex queries; furthermore, we shortly introduce TIGER in, a graphical user interface for query input. The paper concludes with a summary and some directions for future work.",
issn="1572-8706",
doi="10.1007/s11168-004-7431-3",
url="https://doi.org/10.1007/s11168-004-7431-3"
}

@inproceedings{Foth14,
    author = {Kilian Foth and Arne K{\"o}hn and Niels Beuck and Wolfgang
Menzel},
    title = {Because Size Does Matter: The Hamburg Dependency Treebank},
    booktitle = {Proceedings of the Language Resources and Evaluation
Conference 2014 / European Language Resources Association (ELRA)},
    year = {2014},
    publisher = {Universit{\"a}t Hamburg},
    language = {eng},
}

@inproceedings{nakagawa2001unknown,
  title={Unknown Word Guessing and Part-of-Speech Tagging Using Support Vector Machines.},
  author={Nakagawa, Tetsuji and Kudo, Taku and Matsumoto, Yuji},
  booktitle={NLPRS},
  pages={325--331},
  year={2001}
}

@techreport{schiller1999,
  title={Guidelines fuer das Tagging deutscher Textcorpora mit STTS (kleines und großes Tagset)},
  author={Anne Schiller and Simone Teufel and Christine Stoeckert and Christine Thielen},
  institution={Universitaet Stuttgart, Universitaet Tuebingen},
  year={1999}
}

@article{petrov2011universal,
  title={A universal part-of-speech tagset},
  author={Petrov, Slav and Das, Dipanjan and McDonald, Ryan},
  journal={arXiv preprint arXiv:1104.2086},
  year={2011}
}




@misc{word2vecComment,
  title = {word2vec commented},
  author = {McCormick, Chris},
  howpublished = {\url{https://github.com/chrisjmccormick/word2vec_commented}},
  note = {Accessed: 2017-06-22},
  year={2017}
}







@inproceedings{Brill:1992:SRP:1075527.1075553,
 author = {Brill, Eric},
 title = {A Simple Rule-based Part of Speech Tagger},
 booktitle = {Proceedings of the Workshop on Speech and Natural Language},
 series = {HLT '91},
 year = {1992},
 isbn = {1-55860-272-0},
 location = {Harriman, New York},
 pages = {112--116},
 publisher = {Association for Computational Linguistics}
} 

http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\#sklearn.preprocessing.StandardScaler

http://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/tiger.html


@BOOK{Con97,
  AUTHOR =       "Stefan Conrad",
  TITLE =        "{F{\"o}derierte Datenbanksysteme: Konzepte der Datenintegration}",
  PUBLISHER =    "Springer Verlag",
  YEAR =         "1997",
  address =      "Berlin",
}

@article{rong2014word2vec,
  title={word2vec parameter learning explained},
  author={Rong, Xin},
  journal={arXiv preprint arXiv:1411.2738},
  year={2014}
}

@inproceedings{morin2005hierarchical,
  title={Hierarchical Probabilistic Neural Network Language Model.},
  author={Morin, Frederic and Bengio, Yoshua},
  booktitle={Aistats},
  volume={5},
  pages={246--252},
  year={2005}
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}

@article{bengio2007scaling,
  title={Scaling learning algorithms towards AI},
  author={Bengio, Yoshua and LeCun, Yann and others},
  journal={Large-scale kernel machines},
  volume={34},
  number={5},
  pages={1--41},
  year={2007}
}

@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2},
  pages={3},
  year={2010}
}

@article{hinton1984distributed,
  title={Distributed representations},
  author={Hinton, Geoffrey E},
  year={1984}
}

@inproceedings{le2014distributed,
  title={Distributed representations of sentences and documents},
  author={Le, Quoc and Mikolov, Tomas},
  booktitle={Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
  pages={1188--1196},
  year={2014}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@article{goldberg2014word2vec,
  title={word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
  author={Goldberg, Yoav and Levy, Omer},
  journal={arXiv preprint arXiv:1402.3722},
  year={2014}
}

@article{mikolov2013exploiting,
  title={Exploiting similarities among languages for machine translation},
  author={Mikolov, Tomas and Le, Quoc V and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1309.4168},
  year={2013}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library}
}

@article{rumelhart1988learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and others},
  journal={Cognitive modeling},
  volume={5},
  number={3},
  pages={1},
  year={1988}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation.},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={EMNLP},
  volume={14},
  pages={1532--1543},
  year={2014}
}

@article{meyer2016exactly,
  title={How exactly does word2vec work?},
  author={Meyer, David},
  year={2016}
}

@article{deerwester1990indexing,
  title={Indexing by latent semantic analysis},
  author={Deerwester, Scott and Dumais, Susan T and Furnas, George W and Landauer, Thomas K and Harshman, Richard},
  journal={Journal of the American society for information science},
  volume={41},
  number={6},
  pages={391},
  year={1990},
  publisher={American Documentation Institute}
}

@inproceedings{mikolov2013linguistic,
  title={Linguistic regularities in continuous space word representations.},
  author={Mikolov, Tomas and Yih, Wen-tau and Zweig, Geoffrey},
  booktitle={hlt-Naacl},
  volume={13},
  pages={746--751},
  year={2013}
}

@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}

@misc{word2vec,
  key = {Google Code Archive word2vec},
  title = {Google Code Archive: word2vec},
  howpublished = {\url{https://code.google.com/archive/p/word2vec/}},
  note = {Accessed: 2017-06-22},
  year={2017}
}

@misc{word2vecComment,
  title = {word2vec commented},
  author = {McCormick, Chris},
  howpublished = {\url{https://github.com/chrisjmccormick/word2vec_commented}},
  note = {Accessed: 2017-06-22},
  year={2017}
}

@misc{deeplearning4j,
  key = {Deeplearning4j},
  title = {Word2vec: Neural Word Embeddings in Java - Deeplearning4j: Open-source, Distributed Deep Learning for the JVM},
  howpublished = {\url{http://deeplearning4j.org/word2vec.html}},
  note = {Accessed: 2017-06-22},
  year={2017}
}

@misc{spark,
  key = {Spark MLlib},
  title = {Spark MLlib: word2vec},
  howpublished = {\url{https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec}},
  note = {Accessed: 2017-06-22},
  year={2017}
}

@misc{tensorflow,
  key = {tensorflow word2vec},
  title = {Vector Representations of Words},
  howpublished = {\url{https://www.tensorflow.org/versions/r0.8/tutorials/word2vec/index.html}},
  note = {Accessed: 2017-06-22},
  year={2017}
}

@misc{gensim,
  key = {gensim word2vec},
  title = {gensim: models.word2vec – Deep learning with word2vec},
  howpublished = {\url{http://radimrehurek.com/gensim/models/word2vec.html}},
  note = {Accessed: 2017-06-22},
  year={2017}
}

@misc{wevi,
  title = {wevi: word embedding visual inspector},
  author={Rong, Xin},
  howpublished = {\url{https://ronxin.github.io/wevi/}},
  note = {Accessed: 2017-06-22},
  year={2017}
}

@misc{fromdata,
  title = {skip-gram model – From Data to Decisions},
  author = {Integrated Knowledge Solutions},
  year = {2015},
  howpublished = {\url{https://iksinc.wordpress.com/tag/skip-gram-model/}},
  note = {Accessed: 2017-06-22}
}

@misc{Word2VecTutorial,
  title = {Word2Vec Tutorial - The Skip-Gram Model},
  author = {McCormick, Chris},
  year = {2016},
  howpublished = {\url{http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/}},
  note = {Accessed: 2017-06-22}
}

@misc{amazingPower,
  title = {The amazing power of word vectors},
  author = {Colyer, Adrian },
  year = {2016},
  howpublished = {\url{https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/}},
  note = {Accessed: 2017-06-22}
}


